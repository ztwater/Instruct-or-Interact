file_input [0,1039]
    classdef [0,1039]
        name: Lemmatization [6,19]
        suite [20,1039]
            funcdef [25,1039]
                name: lemmatize_sentence [29,47]
                parameters [47,63]
                    param [48,53]
                        name: self [48,52]
                        operator: , [52,53]
                    param [54,62]
                        name: sentence [54,62]
                suite [64,1039]
                    simple_stmt [73,581]
                        string: """         Remove punctuations of the sentence and tokenizes the input sentence, mark the part of speech tag of each word,         lemmatizes the words with different parameters based on their parts of speech, and stores in a list.         :param sentence: a sentence str         :return: a list of words which have been lemmatized.         >>> lemmatization = Lemmatization()         >>> lemmatization.lemmatize_sentence("I am running in a race.")         ['I', 'be', 'run', 'in', 'a', 'race']         """ [73,580]
                    simple_stmt [637,682]
                        expr_stmt [637,681]
                            name: sentence [637,645]
                            operator: = [646,647]
                            atom_expr [648,681]
                                name: self [648,652]
                                trailer [652,671]
                                    name: remove_punctuation [653,671]
                                trailer [671,681]
                                    name: sentence [672,680]
                    simple_stmt [731,764]
                        expr_stmt [731,763]
                            name: tokens [731,737]
                            operator: = [738,739]
                            atom_expr [740,763]
                                name: word_tokenize [740,753]
                                trailer [753,763]
                                    name: sentence [754,762]
                    simple_stmt [832,864]
                        expr_stmt [832,863]
                            name: tagged_tokens [832,845]
                            operator: = [846,847]
                            atom_expr [848,863]
                                name: pos_tag [848,855]
                                trailer [855,863]
                                    name: tokens [856,862]
                    simple_stmt [911,998]
                        expr_stmt [911,997]
                            name: lemmatized_tokens [911,928]
                            operator: = [929,930]
                            atom [931,997]
                                testlist_comp [932,996]
                                    atom_expr [932,964]
                                        name: self [932,936]
                                        trailer [936,947]
                                            name: lemmatizer [937,947]
                                        trailer [947,957]
                                            name: lemmatize [948,957]
                                        trailer [957,964]
                                            name: token [958,963]
                                    sync_comp_for [965,996]
                                        exprlist [969,979]
                                            name: token [969,974]
                                            operator: , [974,975]
                                            name: tag [976,979]
                                        name: tagged_tokens [983,996]
                    return_stmt [1015,1039]
                        name: lemmatized_tokens [1022,1039]